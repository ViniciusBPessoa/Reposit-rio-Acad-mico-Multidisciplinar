{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Projeto comparação entre algoritmos e modelos de Computação evolutiva"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Achando o diretório em que esse arquivo se encontra "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Obtém o caminho do diretório do script atual\n",
    "script_dir = os.getcwd()\n",
    "\n",
    "# Adiciona o diretório pai ao caminho do sistema\n",
    "sys.path.append(script_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.3.0 (SDL 2.24.2, Python 3.11.6)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    }
   ],
   "source": [
    "import pygame # Nos repositórios de referência essa lib é sempre importada tendo em vista que o gymnasium (gym) utiliza a mesma, deve evitar problemas\n",
    "\n",
    "import time # será utilizada para coletar o período temporal necessário para que algumas funções sejam executadas\n",
    "import numpy as np # numpy por motivos óbvios  \n",
    "\n",
    "import torch # Todas as redes neurais serão criados utilizando PyTorch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from redes_neurais.rede_MLP import MLP\n",
    "from func_aux.auxiliares import *\n",
    "\n",
    "import matplotlib.pyplot as plt # Demonstração de Gráficos e imagens "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# usar GPU compatível com CUDA costuma ser mais rápido\n",
    "if torch.cuda.is_available():\n",
    "    is_gpu = torch.device(\"cuda\")\n",
    "else:\n",
    "    is_gpu = torch.device(\"cpu\")\n",
    "\n",
    "torch.set_default_device(is_gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def joga_jogo(env, rede_neural):\n",
    "\n",
    "    if isinstance(env, str):\n",
    "        env = gym.make(env)\n",
    "\n",
    "    imagem, _ = env.reset()\n",
    "    passos = 0\n",
    "    game_recompenca = 0\n",
    "\n",
    "    while True: # inicializa o loop do jogo\n",
    "        passos += 1 # conta quantas vezes a IA foi requisitada ate o complecionismo do mesmo\n",
    "\n",
    "        acao = escolhe_acao(rede_neural, imagem)\n",
    "\n",
    "        nova_imagem, recompensa, finalizado, truncado, _ = env.step(acao)\n",
    "        done = finalizado or truncado\n",
    "        game_recompenca += recompensa\n",
    "\n",
    "        imagem = nova_imagem\n",
    "\n",
    "        if done:\n",
    "            return rede_neural, passos, game_recompenca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# env, env_name, gamma, qnet, qnet_lr, target_qnet, target_update_freq, replay_size, batch_size, epsilon_f, epsilon_decay_period, NUM_STAPS\n",
    "def treinamento_Foda(env, rede_neural_hidden, geracoes, n_por_geracao, n_selecionados = 2, pais = False, learning_rate = 0.001):\n",
    "    \n",
    "    if isinstance(env, str):\n",
    "        env = gym.make(env)\n",
    "    \n",
    "    individuos = []\n",
    "    \n",
    "    input_dim = env.observation_space.shape[0]  # Número de entradas do ambiente MountainCar-v0\n",
    "    output_dim = env.action_space.n  # Número de ações possíveis no ambiente MountainCar-v0\n",
    "\n",
    "    for indi in range(n_por_geracao):\n",
    "        individuos.append(MLP(input_dim, rede_neural_hidden, output_dim))\n",
    "\n",
    "    lista_geracional = []\n",
    "    recompencas = []\n",
    "\n",
    "    for geracao in range(1,geracoes+1):\n",
    "        contador = 0\n",
    "        for especime_network in individuos:\n",
    "            contador += 1\n",
    "\n",
    "            modelo_final, passos, recompensa_total = joga_jogo(env, especime_network)\n",
    "            lista_geracional.append([modelo_final, recompensa_total])\n",
    "            recompencas.append(recompensa_total)\n",
    "            # print(f'Geração: {geracao}/{geracoes}, Individuo: {contador}/{n_por_geracao}, Recompença: {recompensa_total}')\n",
    "    \n",
    "        pais_selecionados = seleciona_pais(lista_geracional, n_selecionados)\n",
    "\n",
    "        print(f'Geração: {geracao}/{geracoes}, Recompensa: {sorted(recompencas, reverse=True)[:3]}')\n",
    "        if pais:\n",
    "            individuos = computacao_evolutiva_mutador_Cpais(n_por_geracao, pais_selecionados, learning_rate)\n",
    "        else:\n",
    "            individuos = computacao_evolutiva_mutador_Spais(n_por_geracao, pais_selecionados, learning_rate)\n",
    "    \n",
    "    for especime_network in individuos:\n",
    "        contador += 1\n",
    "\n",
    "        modelo_final, passos, recompensa_total = joga_jogo(env, especime_network)\n",
    "        lista_geracional.append([modelo_final, recompensa_total])\n",
    "        recompencas.append(recompensa_total)\n",
    "        selecao_final = seleciona_pais(lista_geracional, 1)\n",
    "        \n",
    "    return selecao_final[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Geração: 1/10, Recompensa: [57.0, 55.0, 23.0]\n",
      "Geração: 2/10, Recompensa: [338.0, 113.0, 69.0]\n",
      "Geração: 3/10, Recompensa: [338.0, 296.0, 210.0]\n",
      "Geração: 4/10, Recompensa: [500.0, 338.0, 296.0]\n",
      "Geração: 5/10, Recompensa: [500.0, 500.0, 355.0]\n",
      "Geração: 6/10, Recompensa: [500.0, 500.0, 500.0]\n",
      "Geração: 7/10, Recompensa: [500.0, 500.0, 500.0]\n",
      "Geração: 8/10, Recompensa: [500.0, 500.0, 500.0]\n",
      "Geração: 9/10, Recompensa: [500.0, 500.0, 500.0]\n",
      "Geração: 10/10, Recompensa: [500.0, 500.0, 500.0]\n"
     ]
    }
   ],
   "source": [
    "env = gym.make(\"CartPole-v1\")\n",
    "rede_melhor = treinamento_Foda(\n",
    "    env = env,\n",
    "    rede_neural_hidden = [36,36],\n",
    "    geracoes = 10,\n",
    "    n_por_geracao = 30,\n",
    "    n_selecionados = 6,\n",
    "    pais = True,\n",
    "    learning_rate = 0.01\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=4, out_features=36, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=36, out_features=36, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=36, out_features=2, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(rede_melhor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def record_video_neuralnet(env, rede_neural, episodes=3, folder='videos/', prefix='CE-video', epsilon=0.0):\n",
    "    \"\"\"\n",
    "    Grava um vídeo a partir de uma política epsilon-greedy definida pela 'qtable' e pelo valor de 'epsilon'.\n",
    "    - env_name: A string do ambiente cadastrada no gymnasium ou uma instância da classe. Ao final, o ambiente é fechado (função `close()`).\n",
    "    - qnet: A rede neural que representa a função Q.\n",
    "    - episodes: Número de episódios completos que serão executados.\n",
    "    - prefiz: Prefixo do nome dos arquivos de vídeo.\n",
    "    - folder: Pasta onde os arquivos de vídeo serão salvos.\n",
    "    - epsilon: Valor do parâmetro da política \"epsilon-greedy\" usada para escolher as ações.\n",
    "    \"\"\"\n",
    "    if isinstance(env, str):\n",
    "        env = gym.make(env, render_mode=\"rgb_array\")\n",
    "\n",
    "    rec_env = gym.wrappers.RecordVideo(env, folder, episode_trigger=lambda i : True, name_prefix=prefix)\n",
    "    \n",
    "    num_steps = 0\n",
    "    for epi in range(episodes):\n",
    "        imagem, _ = rec_env.reset()\n",
    "        num_steps += 1\n",
    "        epi_reward = 0.0\n",
    "        done = False\n",
    "        while not done:\n",
    "            action = escolhe_acao(rede_neural, imagem)\n",
    "            imagem, r, termi, trunc, _ = rec_env.step(action)\n",
    "            done = termi or trunc\n",
    "            num_steps += 1\n",
    "            epi_reward += r\n",
    "        print(f\"Episode {epi}: {num_steps} steps / return {epi_reward:.2f}\")\n",
    "    rec_env.close()\n",
    "    env.close()\n",
    "\n",
    "    # Imprimir o caminho completo dos vídeos salvos\n",
    "    for i in range(episodes):\n",
    "        video_path = os.path.join(folder, f\"{prefix}{i}.mp4\")\n",
    "        print(f\"Caminho completo do vídeo {i}: {video_path}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 0: 55 steps / return 54.00\n",
      "Episode 1: 123 steps / return 67.00\n",
      "Episode 2: 173 steps / return 49.00\n",
      "Caminho completo do vídeo 0: videos/CE-video0.mp4\n",
      "Caminho completo do vídeo 1: videos/CE-video1.mp4\n",
      "Caminho completo do vídeo 2: videos/CE-video2.mp4\n"
     ]
    }
   ],
   "source": [
    "record_video_neuralnet(env, rede_melhor, 3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "APR24",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
